{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mMaRuf1998/Banking-App/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62fb2a3b",
        "outputId": "a115bc5f-a57c-483a-db94-9174b4d5f15b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/160.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2023.11.17)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n",
            "Installing collected packages: wfdb\n",
            "Successfully installed wfdb-4.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb\n"
      ],
      "id": "62fb2a3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikx_CFDHbsRj",
        "outputId": "4a246101-ed3c-4f08-958f-72c1612b4a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ],
      "id": "Ikx_CFDHbsRj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "18c5de3e",
        "outputId": "077c734f-67ca-47cc-f73d-9ac589248c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data Loaded. Compiling...\n",
            "\n",
            "Loading data... \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-45619540a5b1>:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_train = np.asarray(pickle.load(f))\n",
            "<ipython-input-6-45619540a5b1>:36: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_val = np.asarray(pickle.load(f))\n",
            "<ipython-input-6-45619540a5b1>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_test = np.asarray(pickle.load(f))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.82091433 1.27902412]\n",
            "Compilation Time :  0.018828868865966797\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 240, 2)]             0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 240, 256)             265216    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 240, 256)             525312    ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 2)]                  0         []                            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 256)                  525312    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 32)                   96        ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 288)                  0         ['lstm_2[0][0]',              \n",
            "                                                                     'dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 8)                    2312      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    9         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 1)                    0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1318257 (5.03 MB)\n",
            "Trainable params: 1318257 (5.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Training\n",
            "2\n",
            "Epoch 1/1000\n",
            "54/54 [==============================] - 1043s 19s/step - loss: 0.6450 - accuracy: 0.6379 - val_loss: 0.6397 - val_accuracy: 0.6390\n",
            "Epoch 2/1000\n",
            "54/54 [==============================] - 1000s 19s/step - loss: 0.6554 - accuracy: 0.5299 - val_loss: 0.6313 - val_accuracy: 0.5187\n",
            "Epoch 3/1000\n",
            "54/54 [==============================] - 969s 18s/step - loss: 0.6431 - accuracy: 0.6173 - val_loss: 0.5791 - val_accuracy: 0.7261\n",
            "Epoch 4/1000\n",
            "33/54 [=================>............] - ETA: 6:04 - loss: 0.5740 - accuracy: 0.7079"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import wfdb\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Hyper-parameters\n",
        "sequence_length = 240\n",
        "epochs = 1000#int(input('Enter Number of Epochs (or enter default 1000): '))\n",
        "FS = 100.0\n",
        "\n",
        "def z_norm(result):\n",
        "    result_mean = np.mean(result)\n",
        "    result_std = np.std(result)\n",
        "    result = (result - result_mean) / result_std\n",
        "    return result\n",
        "\n",
        "def split_data(X):\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    for index in range(len(X)):\n",
        "        X1.append([X[index][0], X[index][1]])\n",
        "        X2.append([X[index][2], X[index][3]])\n",
        "\n",
        "    return np.array(X1).astype('float64'), np.array(X2).astype('float64')\n",
        "\n",
        "def get_data():\n",
        "    with open('/content/drive/MyDrive/Apnea_Data/train_input.pickle','rb') as f:\n",
        "        X_train = np.asarray(pickle.load(f))\n",
        "    with open('/content/drive/MyDrive/Apnea_Data/train_label.pickle','rb') as f:\n",
        "        y_train = np.asarray(pickle.load(f))\n",
        "    with open('/content/drive/MyDrive/Apnea_Data/val_input.pickle','rb') as f:\n",
        "        X_val = np.asarray(pickle.load(f))\n",
        "    with open('/content/drive/MyDrive/Apnea_Data/val_label.pickle','rb') as f:\n",
        "        y_val = np.asarray(pickle.load(f))\n",
        "    with open('/content/drive/MyDrive/Apnea_Data/test_input.pickle','rb') as f:\n",
        "        X_test = np.asarray(pickle.load(f))\n",
        "    with open('/content/drive/MyDrive/Apnea_Data/test_label.pickle','rb') as f:\n",
        "        y_test = np.asarray(pickle.load(f))\n",
        "\n",
        "\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "    '''\n",
        "    X_train = X_train[:, 0, :]\n",
        "    X_test = X_test[:, 0, :]\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "    '''\n",
        "    X_train1, X_train2 = split_data(X_train)\n",
        "    X_val1, X_val2 = split_data(X_val)\n",
        "    X_test1, X_test2 = split_data(X_test)\n",
        "\n",
        "    X_train1 = np.transpose(X_train1, (0, 2, 1))\n",
        "    #X_train2 = np.reshape(X_train2, (X_train2.shape[0], X_train2.shape[1], 1))\n",
        "    X_test1 = np.transpose(X_test1, (0, 2, 1))\n",
        "    #X_test2 = np.reshape(X_test2, (X_test2.shape[0], X_test2.shape[1], 1))\n",
        "    X_val1 = np.transpose(X_val1, (0, 2, 1))\n",
        "    return X_train1, X_train2, y_train, X_val1, X_val2, y_val, X_test1, X_test2, y_test\n",
        "\n",
        "\n",
        "\n",
        "def build_model():\n",
        "\n",
        "    layers = {'input': 2, 'hidden1': 256, 'hidden2': 256, 'hidden3': 256, 'output': 1}\n",
        "    x1 = tf.keras.layers.Input(shape=(sequence_length, layers['input']))\n",
        "    m1 = tf.keras.layers.LSTM(layers['hidden1'],\n",
        "                    recurrent_dropout=0.5,\n",
        "                   return_sequences=True)(x1)\n",
        "    m1 = tf.keras.layers.LSTM(\n",
        "            layers['hidden2'],\n",
        "            recurrent_dropout=0.5,\n",
        "            return_sequences=True)(m1)\n",
        "\n",
        "    m1 = tf.keras.layers.LSTM(\n",
        "            layers['hidden3'],\n",
        "            recurrent_dropout=0.5,\n",
        "            return_sequences=False)(m1)\n",
        "\n",
        "    x2 = tf.keras.layers.Input(shape=(2,))\n",
        "    m2 = tf.keras.layers.Dense(32)(x2)\n",
        "\n",
        "    #merged = Merge([model1, model2], mode='concat')\n",
        "    merged = tf.keras.layers.Concatenate(axis=1)([m1, m2])\n",
        "\n",
        "    out = tf.keras.layers.Dense(8)(merged)\n",
        "    out = tf.keras.layers.Dense(layers['output'], kernel_initializer='normal')(out)\n",
        "    out = tf.keras.layers.Activation(\"sigmoid\")(out)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[x1, x2], outputs=[out])\n",
        "\n",
        "    start = time.time()\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "                  metrics = ['accuracy'])\n",
        "    print (\"Compilation Time : \", time.time() - start)\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_network(model=None, data=None):\n",
        "    global_start_time = time.time()\n",
        "\n",
        "    print ('\\nData Loaded. Compiling...\\n')\n",
        "    print('Loading data... ')\n",
        "    X_train1, X_train2, y_train, X_val1, X_val2, y_val, X_test1, X_test2, y_test = get_data()\n",
        "\n",
        "    class_w = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                     classes=np.unique(y_train),\n",
        "                                                     y=y_train)\n",
        "\n",
        "    print (class_w)\n",
        "\n",
        "    if model is None:\n",
        "        model = build_model()\n",
        "\n",
        "    try:\n",
        "        print(\"Training\")\n",
        "        print(len(class_w));\n",
        "        class_w = {i : class_w[i] for i in range(2)}\n",
        "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "        history = model.fit([X_train1, X_train2], y_train,\n",
        "                            validation_data=([X_val1, X_val2], y_val),\n",
        "                            callbacks=[callback],\n",
        "                             epochs=epochs, batch_size=256, class_weight=class_w)\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        '''\n",
        "        plt.plot(history.losses)\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train'], loc='upper left')\n",
        "        plt.show()\n",
        "        '''\n",
        "        # Evaluate Model\n",
        "        y_pred = model.predict([X_test1, X_test2])\n",
        "        scores = model.evaluate([X_test1, X_test2], y_test)\n",
        "        print(\"%s: %.2f%%  heloooooooooooooooooooooooo\" % (model.metrics_names[1], scores[1] * 100))\n",
        "\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"prediction exception\")\n",
        "        print ('Training duration (s) : ', time.time() - global_start_time)\n",
        "        return model\n",
        "\n",
        "\n",
        "    print ('Training duration (s) : ', time.time() - global_start_time)\n",
        "\n",
        "    return model\n",
        "\n",
        "run_network()"
      ],
      "id": "18c5de3e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLlHcTJavEHK",
        "outputId": "e9b4efe1-943a-4b85-8cf5-02c7a590651c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "id": "vLlHcTJavEHK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2E3eXO39Ofz"
      },
      "outputs": [],
      "source": [],
      "id": "D2E3eXO39Ofz"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}